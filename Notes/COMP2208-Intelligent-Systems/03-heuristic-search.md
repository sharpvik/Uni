# Informed (Heuristic) Search

This section explores benefits of using informed search strategies. Heuristic
search strategies use **problem-specific knowledge** to improve search
efficiency.

## Best-First Search

Best-first search is an instance of the general Tree-Search algorithm in which
we select nodes for expansion based on an **evaluation function** _f(n)_.

> The evaluation function is construed as a cost estimate, so the node with the
> lowest evaluation is expanded first.

Most best-first algorithms include as a component of _f_ a
**heuristic function** _h(n)_ that takes a node and estimates the cost of the
chepest path from the state at node _n_ to the goal state.

> Heuristic functions are the common way in which problem-specific knowledge is
> incorporated into the solving algorithm.

## Greedy Best-Frist Search

Greedy best-first search tried to expand the node that is closest to the goal,
assuming that this is likelt to lead to a solution quickly.

> G-BFS evaluates nodes by using just the heuristic function s.t.
> _f(n) = h(n)_.

Just like most greedy algorithms, it is **not optimal**, however it's more
efficient than most blind search algorithms (assuming that the heuristic is
useful). **G-BFS** is also **not always complete** since its heuristic might
lead it to a dead end.

Its time and space complexity are _O(b<sup>m</sup>)_, however, a good heuristic
can drammatically improve these.

## A\* Search

> The idea is to avoid expensive paths. In this case, our evaluation function
> _f(n) = g(n) + h(n)_ where _g(n)_ returns the **cost so far** and _h(n)_
> return potential estimation of the **future cost**.

A\* search is a heuristic variation of the **Uniform-Cost Search**.

> A\* with an admissible and consisten heuristic is **complete and optimal**.

### Conditions for optimality: Admissibility and Consistency

#### Admissibility

An **admissible heuristic** is one that never _overestimates_ the cost of
reaching the goal state. One such example is the _straight line heuristic_ for
the Romanian map problem: the straight line solution always costs less than
or equal to the real world scenario.

#### Consistency (Monotonicity)

It is only required for applications of A\* to graph search.

A heuristic _h(n)_ is consistent if, for every node _n_ and every successor
_n'_ of _n_ generated by any action _a_, the estimated cost of reaching the
goal from _n_ is no greater than the step cost of getting to _n'_ plus the
estimated cost of reaching the goal from _n'_.

> _h(n) ≤ c(n, a, n') + h(n')_

In other words:

> Our heuristic function should return such values that getting from state
> _n_ to state _G_ is always estimates to be cheaper with one step _n - G_
> rather than with two or more steps like _n - n' - G_.

## Heuristic Dominance

> Given two admissible heuristic functions _h<sub>1</sub>_ and _h<sub>2</sub>_
> s.t. _h<sub>1</sub>(n) ≥ h<sub>2</sub>(n)_, we say that _h<sub>1</sub>_
> dominates _h<sub>2</sub>_. Dominant heuristic function is better for search
> as it gives **more accurate predictions**.

## Coming Up With Appropriate Heuristics (Relaxed Problems)

> A **relaxed problem** is a problem that mimics the initial problem but puts
> fewer restrictions on the actions.

> The cost of an optimal solution for the relaxed problem is an
> **admissible heuristic** for the original problem as it is obviously
> optimistic.

An example of such problem would be an 8-puzzle where we are allowed to swap
two tiles in place. This relaxed problem leads to the Manhattan sum heuristic.
